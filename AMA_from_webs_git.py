import logging
import traceback
import json
import re
import time
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import chromedriver_autoinstaller
import os
import subprocess
import pytz

log_dir = os.path.join(os.getcwd(), "logs")
os.makedirs(log_dir, exist_ok=True)
logging.basicConfig(
    filename=os.path.join(log_dir, "crawler_log.txt"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    encoding="utf-8"  # âœ… ì¸ì½”ë”© ëª…ì‹œ!
)

def save_error_to_json(error_msg, source="KATA"):
    error_log = {
        "timestamp": datetime.now().isoformat(),
        "source": source,
        "error": error_msg
    }
    log_dir = os.path.join(os.getcwd(), "logs")
    os.makedirs(log_dir, exist_ok=True)
    with open(os.path.join(log_dir, "errors.json"), "a", encoding="utf-8") as f:
        json.dump(error_log, f, ensure_ascii=False)
        f.write("\n")

# === ë©”ì¸ KATA í•¨ìˆ˜ ===
def KATA():

    logging.info("KATA í¬ë¡¤ë§ ì‹œì‘")
    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        # chrome_options.add_argument('--ignore-certificate-errors')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
        driver = webdriver.Chrome(options=chrome_options)

        driver.get("http://tennis.sportsdiary.co.kr/tennis/tnrequest/list.asp")
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.competition_list > dl > dd"))
        )
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        dd_elements = soup.select("div.competition_list > dl > dd")

        apply_selectors = []
        rule_selectors = []

        for idx, dd in enumerate(dd_elements, start=1):
            r_con = dd.select_one("span.r_con")
            if not r_con:
                continue
            links = r_con.find_all("a")
            for a in links:
                text = a.get_text(strip=True)
                if "ì‹ ì²­í•˜ê¸°" in text:
                    apply_selectors.append(
                        f"div.competition_list > dl > dd:nth-of-type({idx}) a.sm_btn.green_btn")
                elif "ìš”ê°•ë³´ê¸°" in text and "href" in a.attrs:
                    rule_selectors.append(
                        f"div.competition_list > dl > dd:nth-of-type({idx}) a[href*='bo_table=program']")

        rule_result = []
        for selector in rule_selectors:
            try:
                WebDriverWait(driver, 10).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, selector))).click()
                driver.switch_to.window(driver.window_handles[-1])

                target_elem = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "body > table > tbody > tr:nth-child(2) > td > table > tbody > tr > td:nth-child(4) > table > tbody > tr:nth-child(4) > td > table:nth-child(3) > tbody > tr > td > table:nth-child(2) > tbody > tr:nth-child(1) > td"))
                )
                target_elem0 = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "body > table > tbody > tr:nth-child(2) > td > table > tbody > tr > td:nth-child(4) > table > tbody > tr:nth-child(4) > td > table:nth-child(3) > tbody > tr > td > table:nth-child(1) > tbody > tr > td > b > font"))
                )

                raw0_text = target_elem0.text.strip()
                raw_text = target_elem.text.strip()

                ëŒ€íšŒëª… = re.sub(r"^\[.*?\]\s*", "", raw0_text).strip()
                match = re.search(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", raw_text)
                if match:
                    year = match.group(1)
                    month = match.group(2).zfill(2)
                    day = match.group(3).zfill(2)
                    ëŒ€íšŒê¸°ê°„ = f"{year}.{month}.{day}"
                else:
                    ëŒ€íšŒê¸°ê°„ = ""

                rule_result.append({
                    "ëŒ€íšŒëª…": ëŒ€íšŒëª…,
                    "ëŒ€íšŒê¸°ê°„": ëŒ€íšŒê¸°ê°„
                })

                driver.close()
                driver.switch_to.window(driver.window_handles[0])
                time.sleep(1)

            except Exception as e:
                err_msg = traceback.format_exc()
                logging.warning(f"[ìš”ê°• íŒŒì‹± ì˜¤ë¥˜] {err_msg}")
                save_error_to_json(err_msg, source="KATA - ìš”ê°•íƒ­")

        apply_result = []
        for selector in apply_selectors:
            try:
                driver.get("http://tennis.sportsdiary.co.kr/tennis/tnrequest/list.asp")
                WebDriverWait(driver, 10).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, selector))).click()

                ì¢…ë¥˜ = "ë³µì‹"
                ì£¼ê´€ì‚¬ = "KATA"
                span_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "#frm_in > div.l_apply > div.deposit_info > span"))
                )
                span_text = span_element.text.strip()
                ëŒ€íšŒëª… = re.sub(r"^\[.*?\]\s*", "", span_text).strip()
                match = re.search(r'\[(.*?)\]', span_text)
                ê·¸ë£¹ = match.group(1).strip() if match else ""

                option_elements = driver.find_elements(By.CSS_SELECTOR, "#levelno > option")

                for opt in option_elements:
                    time.sleep(1)
                    value = opt.get_attribute("value").strip()
                    text = opt.text.strip()
                    if not value:
                        continue
                    numbers = re.findall(r"(\d+)\s*/\s*(\d+)(?![^()]*\))", text)
                    if numbers:
                        í˜„ì›, ì •ì› = numbers[-1]
                        ë¶€ì„œ = re.split(r"\d+\s*/\s*\d+(?![^()]*\))", text)[0].strip()
                        entry = {
                            "ì¢…ë¥˜": ì¢…ë¥˜,
                            "ì£¼ê´€ì‚¬": ì£¼ê´€ì‚¬,
                            "ê·¸ë£¹": ê·¸ë£¹,
                            "ëŒ€íšŒëª…": ëŒ€íšŒëª…,
                            "ë¶€ì„œ": ë¶€ì„œ,
                            "í˜„ì›": í˜„ì›,
                            "ì •ì›": ì •ì›,
                            "ì°¸ê°€ì‹ ì²­ ë§í¬": 'http://tennis.sportsdiary.co.kr/tennis/tnrequest/list.asp'
                        }
                        matching = next((r for r in rule_result if r["ëŒ€íšŒëª…"] == ëŒ€íšŒëª…), None)
                        if matching:
                            entry["ëŒ€íšŒê¸°ê°„"] = matching["ëŒ€íšŒê¸°ê°„"]
                        apply_result.append(entry)
            except Exception as e:
                err_msg = traceback.format_exc()
                logging.warning(f"[ì‹ ì²­íƒ­ íŒŒì‹± ì˜¤ë¥˜] {err_msg}")
                save_error_to_json(err_msg, source="KATA - ì‹ ì²­íƒ­")

        logging.info(f"KATA í¬ë¡¤ë§ ì™„ë£Œ / ì´ í•­ëª© ìˆ˜: {len(apply_result)}")
        return apply_result

    except Exception as e:
        err_msg = traceback.format_exc()
        logging.error(f"KATA ì „ì²´ ì˜¤ë¥˜: {err_msg}")
        save_error_to_json(err_msg, source="KATA")
        return []

    finally:
        if driver:
            driver.quit()
def KTA():
    logging.info("KTA í¬ë¡¤ë§ ì‹œì‘")
    driver = None
    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument('--ignore-certificate-errors')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
        driver = webdriver.Chrome(options=chrome_options)


        url_main = 'https://join.kortennis.or.kr/index.do'
        url_tournaments = 'https://join.kortennis.or.kr/sportsForAll/sportsForAll.do?_code=10078'
        driver.get(url_main)
        driver.get(url_tournaments)

        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#cnt03"))).click()
        time.sleep(2)

        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "#divisionLegList tbody tr")))
        trs = driver.find_elements(By.CSS_SELECTOR, "#divisionLegList tbody tr")
        selector_list = []

        for i in range(1, len(trs) + 1):
            selector = f"#divisionLegList > tbody > tr:nth-child({i}) > td:nth-child(3) > div > button:nth-child(1)"
            try:
                driver.find_element(By.CSS_SELECTOR, selector)
                selector_list.append(selector)
            except:
                logging.warning(f"[ìŠ¤í‚µ] {selector}")
                continue

        result_data = []
        for selector in selector_list:
            try:
                WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector))).click()
                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, "#group")))

                ì¢…ë¥˜ = "ë³µì‹"
                ì£¼ê´€ì‚¬ = "KTA"
                ê·¸ë£¹ = driver.find_element(By.CSS_SELECTOR, "#group").text.strip()
                ëŒ€íšŒëª… = driver.find_element(By.CSS_SELECTOR, "#cmptNm").text.strip()
                ëŒ€íšŒê¸°ê°„ = driver.find_element(By.CSS_SELECTOR, "#cmptDt").text.strip()
                ì¥ì†Œ = driver.find_element(By.CSS_SELECTOR, "#place").text.strip()

                tab_button = driver.find_element(By.CSS_SELECTOR, "#btnTab > div > div > div:nth-child(2) > div > li > a")
                driver.execute_script("arguments[0].click();", tab_button)
                time.sleep(1)

                WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "#cmptApplyEventList")))
                rows = driver.find_elements(By.CSS_SELECTOR, "#cmptApplyEventList > tr")

                for i in range(1, len(rows)+1):
                    try:
                        ë¶€ì„œ = driver.find_element(By.CSS_SELECTOR, f"#cmptApplyEventList > tr:nth-child({i}) > td:nth-child(1)").text.strip()
                        ê²½ê¸°ì¼ì‹œ = driver.find_element(By.CSS_SELECTOR, f"#cmptApplyEventList > tr:nth-child({i}) > td:nth-child(4)").text.strip()
                        í˜„ì •ì› = driver.find_element(By.CSS_SELECTOR, f"#cmptApplyEventList > tr:nth-child({i}) > td:nth-child(6)").text.strip()

                        if '/' in í˜„ì •ì›:
                            í˜„ì›, ì •ì› = [x.strip() for x in í˜„ì •ì›.split('/')]
                        else:
                            í˜„ì›, ì •ì› = '', ''

                        result_data.append({
                            "ì¢…ë¥˜": ì¢…ë¥˜,
                            "ì£¼ê´€ì‚¬": ì£¼ê´€ì‚¬,
                            "ê·¸ë£¹": ê·¸ë£¹,
                            "ëŒ€íšŒëª…": ëŒ€íšŒëª…,
                            "ëŒ€íšŒê¸°ê°„": ëŒ€íšŒê¸°ê°„,
                            "ì¥ì†Œ": ì¥ì†Œ,
                            "ë¶€ì„œ": ë¶€ì„œ,
                            "ê²½ê¸°ì¼ì‹œ": ê²½ê¸°ì¼ì‹œ,
                            "í˜„ì›": í˜„ì›,
                            "ì •ì›": ì •ì›,
                            "ì°¸ê°€ì‹ ì²­ ë§í¬": "https://join.kortennis.or.kr/index.do",
                        })
                    except Exception as e:
                        err_msg = traceback.format_exc()
                        logging.warning(f"[KTA ë¶€ì„œë³„ í•­ëª© íŒŒì‹± ì˜¤ë¥˜] {err_msg}")
                        save_error_to_json(err_msg, source="KTA - ë¶€ì„œ íŒŒì‹±")
                driver.back()

            except Exception as e:
                err_msg = traceback.format_exc()
                logging.warning(f"[KTA ê°œë³„ ëŒ€íšŒ ì§„ì… ì˜¤ë¥˜] {err_msg}")
                save_error_to_json(err_msg, source="KTA - ê°œë³„ ëŒ€íšŒ")

        logging.info(f"KTA í¬ë¡¤ë§ ì™„ë£Œ / ì´ í•­ëª© ìˆ˜: {len(result_data)}")
        return result_data

    except Exception as e:
        err_msg = traceback.format_exc()
        logging.error(f"KTA ì „ì²´ ì˜¤ë¥˜: {err_msg}")
        save_error_to_json(err_msg, source="KTA")
        return []

    finally:
        if driver:
            driver.quit()
def KATO():
    logging.info("KATO í¬ë¡¤ë§ ì‹œì‘")
    driver = None
    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument('--ignore-certificate-errors')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
        driver = webdriver.Chrome(options=chrome_options)


        driver.get("https://www.kato.kr/")
        time.sleep(2)

        containers = driver.find_elements(By.CSS_SELECTOR, "div.gtco-services.gtco-section")
        tournaments = containers[1].find_elements(By.CSS_SELECTOR, "div.service-wrap > div.service")
        all_data = []

        for i in range(len(tournaments)):
            try:
                logging.info(f"{i+1}ë²ˆì§¸ ëŒ€íšŒ í´ë¦­ ì‹œë„")
                containers = driver.find_elements(By.CSS_SELECTOR, "div.gtco-services.gtco-section")
                tournaments = containers[1].find_elements(By.CSS_SELECTOR, "div.service-wrap > div.service")
                tournaments[i].click()
                time.sleep(2)

                try:
                    tab = driver.find_element(By.CSS_SELECTOR, "#gameTap > li:nth-child(2) > a")
                    tab.click()
                    time.sleep(1)
                except Exception as e:
                    err_msg = traceback.format_exc()
                    logging.warning(f"[ì°¸ê°€ì‹ ì²­ íƒ­ í´ë¦­ ì‹¤íŒ¨] {err_msg}")
                    save_error_to_json(err_msg, source="KATO - ì°¸ê°€ì‹ ì²­ íƒ­")
                    driver.back()
                    time.sleep(2)
                    continue

                title = driver.find_element(By.CSS_SELECTOR, "div.group-title").text.strip()
                rows = driver.find_elements(By.CSS_SELECTOR, "#tab2 > div > table > tbody > tr")

                for row in rows:
                    try:
                        dept = row.find_element(By.CSS_SELECTOR, "td:nth-child(1)").text.strip()
                        date = row.find_element(By.CSS_SELECTOR, "td.rightnone > div:nth-child(1)").text.strip()
                        location = row.find_element(By.CSS_SELECTOR, "td.rightnone > div.place").text.strip()

                        match = re.search(r"(\d{4})ë…„\s*(\d{2})ì›”\s*(\d{2})ì¼", date)
                        formatted_date = f"{match.group(1)}.{match.group(2)}.{match.group(3)}" if match else date

                        take_span = row.find_elements(By.CSS_SELECTOR, "td.leftnone > span.takeparting, td.leftnone > span.takepartingOver")
                        if take_span:
                            now, total = [x.strip() for x in take_span[0].text.strip().split('/')]
                        else:
                            now, total = '', ''

                        all_data.append({
                            "ì¢…ë¥˜": "ë³µì‹",
                            "ì£¼ê´€ì‚¬": "KATO",
                            "ëŒ€íšŒëª…": title,
                            "ëŒ€íšŒê¸°ê°„": formatted_date,
                            "ì¥ì†Œ": location,
                            "ë¶€ì„œ": dept,
                            "ê²½ê¸°ì¼ì‹œ": formatted_date,
                            "í˜„ì›": now,
                            "ì •ì›": total,
                            "ì°¸ê°€ì‹ ì²­ ë§í¬": "https://www.kato.kr/"
                        })

                    except Exception as e:
                        err_msg = traceback.format_exc()
                        logging.warning(f"[KATO í–‰ íŒŒì‹± ì˜¤ë¥˜] {err_msg}")
                        save_error_to_json(err_msg, source="KATO - row")

                driver.back()
                time.sleep(2)

            except Exception as e:
                err_msg = traceback.format_exc()
                logging.warning(f"[KATO ëŒ€íšŒ í´ë¦­ ì˜¤ë¥˜] {err_msg}")
                save_error_to_json(err_msg, source="KATO - ëŒ€íšŒ í´ë¦­")

        logging.info(f"KATO í¬ë¡¤ë§ ì™„ë£Œ / ì´ í•­ëª© ìˆ˜: {len(all_data)}")
        return all_data

    except Exception as e:
        err_msg = traceback.format_exc()
        logging.error(f"KATO ì „ì²´ ì˜¤ë¥˜: {err_msg}")
        save_error_to_json(err_msg, source="KATO")
        return []

    finally:
        if driver:
            driver.quit()

def load_previous_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f).get("data", [])
    except FileNotFoundError:
        return []

def merge_with_previous_data(old_data, new_data):
    kst = pytz.timezone("Asia/Seoul")
    now_kst = datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")

    def key(entry):
        return (entry.get("ì£¼ê´€ì‚¬"), entry.get("ëŒ€íšŒëª…"), entry.get("ë¶€ì„œ"))

    old_map = {key(entry): entry for entry in old_data}
    merged = []

    for item in new_data:
        item_key = key(item)
        if item_key in old_map and "new_updated" in old_map[item_key]:
            item["new_updated"] = old_map[item_key]["new_updated"]
        else:
            item["new_updated"] = now_kst
        merged.append(item)

    return merged

def run_daum_kasta_crawler(apply_link="https://cafe.daum.net/singlestennis/WTqa"):
    def normalize_date(text):
        match = re.search(r"(\d{1,2})\.(\d{1,2})", text)
        if match:
            month, day = match.groups()
            return f"2025.{int(month):02}.{int(day):02}"
        return None

    def extract_group(text):
        match = re.search(r"(\d)ê·¸ë£¹", text)
        return match.group(1) if match else None

    def clean_title(text):
        cleaned = re.sub(r"[ğŸ¾ğŸ¥‡ğŸš™ğŸ“®â–²ğŸ‘‰]", "", text).strip()
        return cleaned.split("(")[0].strip()

    url = "https://cafe.daum.net/singlestennis/WUwM"
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    driver = webdriver.Chrome(options=options)

    driver.get(url)
    time.sleep(2)
    driver.switch_to.frame("down")
    time.sleep(1)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    menu_items = soup.select("#menu_folder_list > div.menuListBox > div a")

    data = []
    for item in menu_items:
        title = item.get_text(strip=True)
        href = item.get("href", "")
        full_link = "https://cafe.daum.net" + href if href.startswith("/") else href
        data.append({"title": title, "link": full_link})

    start_idx, end_idx = None, None
    for i, item in enumerate(data):
        if item["title"].strip() == "â–²" and 'toggleFoldingGroupMenu("2")' in item.get("link", ""):
            start_idx = i + 1
        if "ë‹¨ì‹ëŒ€íšŒ ì¹´í’€" in item["title"]:
            end_idx = i
            break

    if start_idx is None or end_idx is None or start_idx >= end_idx:
        logging.warning("âŒ ëŒ€íšŒ êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []

    filtered = [item for item in data[start_idx:end_idx] if "ğŸ¾" in item["title"]]

    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    parsed = []
    for item in filtered:
        raw_title = item["title"]
        date = normalize_date(raw_title)
        group = extract_group(raw_title)
        title = clean_title(raw_title)

        entry = {
            "ì¢…ë¥˜": "ë‹¨ì‹",
            "ì£¼ê´€ì‚¬": "KASTA",
            "ëŒ€íšŒëª…": title,
            "ì°¸ê°€ì‹ ì²­ ë§í¬": apply_link
        }
        if date: entry["ëŒ€íšŒê¸°ê°„"] = date
        if group: entry["ê·¸ë£¹"] = group

        # "new_updated"ëŠ” merge ë‹¨ê³„ì—ì„œ ì²˜ë¦¬
        parsed.append(entry)

    return parsed



if __name__ == "__main__":
    logging.info("=== í¬ë¡¤ë§ ì‘ì—… ì‹œì‘ ===")
    start_time = time.time()

    all_results = []

    for source, func in [("KATA", KATA), ("KTA", KTA), ("KATO", KATO)]:
        try:
            logging.info(f"{source} ì‹œì‘")
            result = func()
            logging.info(f"{source} ì™„ë£Œ / ìˆ˜ì§‘ í•­ëª© ìˆ˜: {len(result)}")
            all_results.extend(result)
        except Exception as e:
            err_msg = traceback.format_exc()
            save_error_to_json(err_msg, source=source)
            logging.error(f"{source} ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ")

    # âœ… KASTA ë‹¨ì‹ ëŒ€íšŒ ìˆ˜ì§‘ ì¶”ê°€
    try:
        logging.info("KASTA ì‹œì‘")
        kasta_results = run_daum_kasta_crawler()
        logging.info(f"KASTA ì™„ë£Œ / ìˆ˜ì§‘ í•­ëª© ìˆ˜: {len(kasta_results)}")
        all_results.extend(kasta_results)
    except Exception as e:
        err_msg = traceback.format_exc()
        save_error_to_json(err_msg, source="KASTA")
        logging.error("KASTA ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ")

    # âœ… ê¸°ì¡´ íŒŒì¼ê³¼ ë¹„êµ í›„ ë³‘í•©
    output_path = os.path.join(os.getcwd(), "tennis_tournaments_ama.json")
    try:
        old_data = load_previous_data(output_path)
        merged_data = merge_with_previous_data(old_data, all_results)

        kst = pytz.timezone("Asia/Seoul")
        now_kst = datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")

        result_with_timestamp = {
            "executed_at": now_kst,
            "data": merged_data
        }
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result_with_timestamp, f, ensure_ascii=False, indent=2)
        logging.info(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    except Exception as e:
        save_error_to_json(traceback.format_exc(), source="Result Saving")

    elapsed = time.time() - start_time
    logging.info(f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    logging.info("=== í¬ë¡¤ë§ ì‘ì—… ì¢…ë£Œ ===")
